/**
 * Gemini LLM ì˜ˆì¸¡ ì—”ì§„
 * ê²½ì£¼ ë°ì´í„° â†’ LLM ì˜ˆì¸¡ â†’ ê²°ê³¼ ì €ì¥
 */

import { getGeminiClient, GeminiApiError } from './client'
import { getPredictionPrompt, PredictionType, PREDICTION_TYPE_INFO } from './prompts'
import { buildRaceContext, buildCompactRaceContext, getContextStats } from '../context/race-context'
import { prisma } from '@/lib/prisma'

// ============================================
// ì˜ˆì¸¡ ê²°ê³¼ íƒ€ì…
// ============================================

export interface PredictionResult {
  id: number
  raceId: number
  predictionType: string
  predictionData: any
  confidenceScore: number
  llmModelVersion: string
  llmReasoning?: string
  createdAt: Date
  metadata?: {
    tokenCount?: number
    processingTime?: number
    contextQuality?: number
  }
}

// ============================================
// ì˜ˆì¸¡ ìƒì„± ì˜µì…˜
// ============================================

export interface PredictionOptions {
  useCompactContext?: boolean // ìš”ì•½ëœ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©
  saveToDatabase?: boolean // DBì— ìë™ ì €ì¥
  temperature?: number // LLM temperature
  maxRetries?: number // ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ íšŸìˆ˜
}

// ============================================
// ì˜ˆì¸¡ ì—”ì§„ í´ë˜ìŠ¤
// ============================================

export class RacePredictionEngine {
  private geminiClient

  constructor() {
    this.geminiClient = getGeminiClient()
  }

  // ============================================
  // ë‹¨ì¼ íƒ€ì… ì˜ˆì¸¡ ìƒì„±
  // ============================================

  async generatePrediction(
    raceId: number,
    type: PredictionType,
    options: PredictionOptions = {}
  ): Promise<PredictionResult> {
    const {
      useCompactContext = false,
      saveToDatabase = true,
      temperature = 0.7,
      maxRetries = 2,
    } = options

    const startTime = Date.now()

    try {
      console.log(`ğŸ¯ ${PREDICTION_TYPE_INFO[type].name} ì˜ˆì¸¡ ìƒì„± ì‹œì‘ (ê²½ì£¼ ID: ${raceId})`)

      // 1. ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•
      const context = useCompactContext
        ? await buildCompactRaceContext(raceId)
        : await buildRaceContext(raceId)

      const stats = await getContextStats(raceId)
      console.log(
        `   ğŸ“Š ì»¨í…ìŠ¤íŠ¸: ${stats.token_estimate} í† í° (ì˜ˆìƒ), ì™„ì „ì„± ${(stats.data_completeness * 100).toFixed(1)}%`
      )

      // 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
      const prompt = getPredictionPrompt(type, context)

      // 3. LLM í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
      let predictionData: any
      let attempt = 0
      let lastError: Error | null = null

      while (attempt <= maxRetries) {
        try {
          predictionData = await this.geminiClient.generateJSON(prompt, {
            temperature,
            maxOutputTokens: 8192,
          })
          break // ì„±ê³µ
        } catch (error) {
          lastError = error as Error
          attempt++
          if (attempt <= maxRetries) {
            console.warn(`   âš ï¸ ì¬ì‹œë„ ${attempt}/${maxRetries}...`)
            await new Promise((resolve) => setTimeout(resolve, 1000 * attempt))
          }
        }
      }

      if (!predictionData) {
        throw new GeminiApiError(
          `ì˜ˆì¸¡ ìƒì„± ì‹¤íŒ¨ (${maxRetries}íšŒ ì¬ì‹œë„): ${lastError?.message}`,
          'PREDICTION_FAILED'
        )
      }

      // 4. ì‹ ë¢°ë„ ì ìˆ˜ ì¶”ì¶œ
      const confidenceScore = this.extractConfidence(predictionData)

      // 5. ì¶”ë¡  ê³¼ì • ì¶”ì¶œ
      const reasoning = this.extractReasoning(predictionData)

      const processingTime = Date.now() - startTime
      console.log(
        `   âœ… ì˜ˆì¸¡ ì™„ë£Œ (${processingTime}ms, ì‹ ë¢°ë„: ${(confidenceScore * 100).toFixed(1)}%)`
      )

      // 6. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
      let result: PredictionResult

      if (saveToDatabase) {
        const saved = await prisma.prediction.create({
          data: {
            raceId,
            predictionType: type,
            predictionData: predictionData as any,
            confidenceScore: confidenceScore.toString(),
            llmModelVersion: this.geminiClient.getModelInfo().name,
            llmReasoning: reasoning,
          },
        })

        result = {
          id: saved.id,
          raceId: saved.raceId,
          predictionType: saved.predictionType,
          predictionData: saved.predictionData,
          confidenceScore: parseFloat(saved.confidenceScore.toString()),
          llmModelVersion: saved.llmModelVersion,
          llmReasoning: saved.llmReasoning || undefined,
          createdAt: saved.createdAt,
          metadata: {
            tokenCount: stats.token_estimate,
            processingTime,
            contextQuality: stats.data_completeness,
          },
        }
      } else {
        result = {
          id: 0,
          raceId,
          predictionType: type,
          predictionData,
          confidenceScore,
          llmModelVersion: this.geminiClient.getModelInfo().name,
          llmReasoning: reasoning,
          createdAt: new Date(),
          metadata: {
            tokenCount: stats.token_estimate,
            processingTime,
            contextQuality: stats.data_completeness,
          },
        }
      }

      return result
    } catch (error) {
      console.error(`âŒ ì˜ˆì¸¡ ìƒì„± ì‹¤íŒ¨:`, error)
      throw error
    }
  }

  // ============================================
  // ë‹¤ì¤‘ íƒ€ì… ì˜ˆì¸¡ ìƒì„± (ë°°ì¹˜)
  // ============================================

  async generateMultiplePredictions(
    raceId: number,
    types: PredictionType[],
    options: PredictionOptions = {}
  ): Promise<PredictionResult[]> {
    console.log(`ğŸ¯ ${types.length}ê°œ íƒ€ì… ì˜ˆì¸¡ ìƒì„± ì‹œì‘ (ê²½ì£¼ ID: ${raceId})`)

    const results: PredictionResult[] = []

    // ìˆœì°¨ ì‹¤í–‰ (ë™ì‹œ ì‹¤í–‰ ì‹œ API Rate Limit ìš°ë ¤)
    for (const type of types) {
      try {
        const result = await this.generatePrediction(raceId, type, options)
        results.push(result)

        // API Rate Limit ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
        await new Promise((resolve) => setTimeout(resolve, 500))
      } catch (error) {
        console.error(`${type} ì˜ˆì¸¡ ì‹¤íŒ¨:`, error)
        // ê³„ì† ì§„í–‰ (ë¶€ë¶„ ì‹¤íŒ¨ í—ˆìš©)
      }
    }

    console.log(`âœ… ${results.length}/${types.length}ê°œ ì˜ˆì¸¡ ìƒì„± ì™„ë£Œ`)
    return results
  }

  // ============================================
  // ì˜ˆì¸¡ ì¡°íšŒ
  // ============================================

  async getPrediction(raceId: number, type: PredictionType): Promise<PredictionResult | null> {
    const prediction = await prisma.prediction.findFirst({
      where: {
        raceId,
        predictionType: type,
      },
      orderBy: {
        createdAt: 'desc',
      },
    })

    if (!prediction) return null

    return {
      id: prediction.id,
      raceId: prediction.raceId,
      predictionType: prediction.predictionType,
      predictionData: prediction.predictionData,
      confidenceScore: parseFloat(prediction.confidenceScore.toString()),
      llmModelVersion: prediction.llmModelVersion,
      llmReasoning: prediction.llmReasoning || undefined,
      createdAt: prediction.createdAt,
    }
  }

  async getAllPredictions(raceId: number): Promise<PredictionResult[]> {
    const predictions = await prisma.prediction.findMany({
      where: { raceId },
      orderBy: {
        createdAt: 'desc',
      },
    })

    return predictions.map((p) => ({
      id: p.id,
      raceId: p.raceId,
      predictionType: p.predictionType,
      predictionData: p.predictionData,
      confidenceScore: parseFloat(p.confidenceScore.toString()),
      llmModelVersion: p.llmModelVersion,
      llmReasoning: p.llmReasoning || undefined,
      createdAt: p.createdAt,
    }))
  }

  // ============================================
  // í—¬í¼ ë©”ì„œë“œ
  // ============================================

  private extractConfidence(predictionData: any): number {
    // ì˜ˆì¸¡ ë°ì´í„°ì—ì„œ ì‹ ë¢°ë„ ì ìˆ˜ ì¶”ì¶œ
    if (predictionData.overall_confidence !== undefined) {
      return Math.max(0, Math.min(1, predictionData.overall_confidence))
    }

    if (predictionData.confidence !== undefined) {
      return Math.max(0, Math.min(1, predictionData.confidence))
    }

    // ê°œë³„ ì˜ˆì¸¡ë“¤ì˜ í‰ê·  ì‹ ë¢°ë„
    if (predictionData.predictions && Array.isArray(predictionData.predictions)) {
      const confidences = predictionData.predictions
        .map((p: any) => p.confidence)
        .filter((c: any) => typeof c === 'number')

      if (confidences.length > 0) {
        return confidences.reduce((a: number, b: number) => a + b) / confidences.length
      }
    }

    // ê¸°ë³¸ê°’
    return 0.5
  }

  private extractReasoning(predictionData: any): string | undefined {
    if (predictionData.race_analysis) {
      return predictionData.race_analysis
    }

    if (predictionData.reasoning) {
      return predictionData.reasoning
    }

    if (predictionData.predictions && predictionData.predictions[0]?.reasoning) {
      return predictionData.predictions[0].reasoning
    }

    return undefined
  }

  // ============================================
  // ì˜ˆì¸¡ ê²€ì¦
  // ============================================

  async validatePrediction(predictionId: number): Promise<{
    valid: boolean
    errors: string[]
    warnings: string[]
  }> {
    const result = {
      valid: true,
      errors: [] as string[],
      warnings: [] as string[],
    }

    const prediction = await prisma.prediction.findUnique({
      where: { id: predictionId },
    })

    if (!prediction) {
      result.valid = false
      result.errors.push('ì˜ˆì¸¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤')
      return result
    }

    // JSON êµ¬ì¡° ê²€ì¦
    try {
      const data = prediction.predictionData as any

      if (!data.predictions || !Array.isArray(data.predictions)) {
        result.valid = false
        result.errors.push('predictions ë°°ì—´ì´ ì—†ìŠµë‹ˆë‹¤')
      }

      if (data.predictions && data.predictions.length === 0) {
        result.warnings.push('ì˜ˆì¸¡ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤')
      }

      const confidence = parseFloat(prediction.confidenceScore.toString())
      if (confidence < 0.3) {
        result.warnings.push(`ë§¤ìš° ë‚®ì€ ì‹ ë¢°ë„: ${(confidence * 100).toFixed(1)}%`)
      }
    } catch (error) {
      result.valid = false
      result.errors.push('ì˜ˆì¸¡ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨')
    }

    return result
  }
}

// ============================================
// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
// ============================================

let predictionEngineInstance: RacePredictionEngine | null = null

export function getPredictionEngine(): RacePredictionEngine {
  if (!predictionEngineInstance) {
    predictionEngineInstance = new RacePredictionEngine()
  }
  return predictionEngineInstance
}

export default getPredictionEngine
