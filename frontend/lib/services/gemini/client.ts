/**
 * Gemini API í´ë¼ì´ì–¸íŠ¸
 * Google Generative AI SDKë¥¼ ì‚¬ìš©í•œ LLM ì˜ˆì¸¡
 */

import { GoogleGenerativeAI, GenerativeModel, GenerationConfig } from '@google/generative-ai'

// ============================================
// ì„¤ì • ìƒìˆ˜
// ============================================

const GEMINI_MODEL = 'gemini-3-flash-preview' // ë¹ ë¥´ê³  ì €ë ´í•œ ëª¨ë¸
const DEFAULT_TEMPERATURE = 0.7 // ì°½ì˜ì„±ê³¼ ì¼ê´€ì„± ê· í˜•
const DEFAULT_MAX_TOKENS = 30000 // ì‘ë‹µ ìµœëŒ€ í† í°
const DEFAULT_TIMEOUT = 30000 // 30ì´ˆ

// ============================================
// Gemini API ì—ëŸ¬ í´ë˜ìŠ¤
// ============================================

export class GeminiApiError extends Error {
  constructor(
    message: string,
    public code?: string,
    public details?: any
  ) {
    super(message)
    this.name = 'GeminiApiError'
  }
}

// ============================================
// Gemini ì‘ë‹µ íƒ€ì…
// ============================================

export interface GeminiResponse {
  text: string
  finishReason: string
  safetyRatings?: any[]
  tokenCount?: {
    promptTokens: number
    responseTokens: number
    totalTokens: number
  }
}

// ============================================
// Generation ì„¤ì • íƒ€ì…
// ============================================

export interface GeminiGenerationOptions {
  temperature?: number
  maxOutputTokens?: number
  topP?: number
  topK?: number
}

// ============================================
// Gemini API í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤
// ============================================

export class GeminiClient {
  private genAI: GoogleGenerativeAI
  private model: GenerativeModel
  private apiKey: string

  constructor(apiKey?: string, modelName: string = GEMINI_MODEL) {
    this.apiKey = apiKey || process.env.GEMINI_API_KEY || ''

    if (!this.apiKey) {
      throw new GeminiApiError(
        'Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.'
      )
    }

    // GoogleGenerativeAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (v1beta API ì‚¬ìš©)
    this.genAI = new GoogleGenerativeAI(this.apiKey, { apiVersion: 'v1beta' })

    // ëª¨ë¸ ìƒì„±
    this.model = this.genAI.getGenerativeModel({
      model: modelName,
    })

    console.log(`âœ… Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: ${modelName})`)
  }

  // ============================================
  // í…ìŠ¤íŠ¸ ìƒì„± (ê¸°ë³¸)
  // ============================================

  async generateText(
    prompt: string,
    options: GeminiGenerationOptions = {}
  ): Promise<GeminiResponse> {
    try {
      const generationConfig: GenerationConfig = {
        temperature: options.temperature ?? DEFAULT_TEMPERATURE,
        maxOutputTokens: options.maxOutputTokens ?? DEFAULT_MAX_TOKENS,
        topP: options.topP,
        topK: options.topK,
      }

      const result = await this.model.generateContent({
        contents: [{ role: 'user', parts: [{ text: prompt }] }],
        generationConfig,
      })

      const response = result.response
      const text = response.text()

      if (!text) {
        throw new GeminiApiError('Gemini APIê°€ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.')
      }

      return {
        text,
        finishReason: response.candidates?.[0]?.finishReason || 'STOP',
        safetyRatings: response.candidates?.[0]?.safetyRatings,
        tokenCount: {
          promptTokens: (result.response as any).usageMetadata?.promptTokenCount || 0,
          responseTokens: (result.response as any).usageMetadata?.candidatesTokenCount || 0,
          totalTokens: (result.response as any).usageMetadata?.totalTokenCount || 0,
        },
      }
    } catch (error: any) {
      console.error('Gemini API ì—ëŸ¬:', error)

      if (error.message?.includes('API key')) {
        throw new GeminiApiError('ìœ íš¨í•˜ì§€ ì•Šì€ API í‚¤ì…ë‹ˆë‹¤.', 'INVALID_API_KEY')
      }

      if (error.message?.includes('quota')) {
        throw new GeminiApiError('API í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.', 'QUOTA_EXCEEDED', error)
      }

      if (error.message?.includes('safety')) {
        throw new GeminiApiError(
          'Gemini ì•ˆì „ í•„í„°ì— ì˜í•´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.',
          'SAFETY_BLOCK',
          error
        )
      }

      throw new GeminiApiError(
        `Gemini API í˜¸ì¶œ ì‹¤íŒ¨: ${error.message}`,
        'API_ERROR',
        error
      )
    }
  }

  // ============================================
  // JSON í˜•ì‹ ì‘ë‹µ ìƒì„±
  // ============================================

  async generateJSON<T = any>(
    prompt: string,
    options: GeminiGenerationOptions = {}
  ): Promise<T> {
    try {
      // JSON ì¶œë ¥ ê°•ì œ
      const jsonPrompt = `${prompt}\n\nì‘ë‹µì€ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.`

      const response = await this.generateText(jsonPrompt, {
        ...options,
        temperature: 0.3, // JSON ìƒì„±ì€ ë‚®ì€ temperature
      })

      // JSON ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
      let jsonText = response.text.trim()

      console.log('ğŸ“ Raw LLM response length:', jsonText.length)
      console.log('ğŸ“ Raw LLM response (first 500):', jsonText.substring(0, 500))
      console.log('ğŸ“ Raw LLM response (last 200):', jsonText.substring(jsonText.length - 200))

      // ```json ... ``` í˜•ì‹ ì œê±° (ë‹«ëŠ” ``` ì—†ì–´ë„ ì²˜ë¦¬)
      if (jsonText.startsWith('```json')) {
        jsonText = jsonText.replace(/^```json\s*/, '').replace(/\s*```\s*$/, '')
      } else if (jsonText.startsWith('```')) {
        jsonText = jsonText.replace(/^```\s*/, '').replace(/\s*```\s*$/, '')
      }

      // JSON ê°ì²´/ë°°ì—´ ì¶”ì¶œ (ì‹œì‘ { ë˜ëŠ” [ ë¶€í„° ë§ˆì§€ë§‰ } ë˜ëŠ” ] ê¹Œì§€)
      const jsonMatch = jsonText.match(/[\[{][\s\S]*[\]}]/)
      if (jsonMatch) {
        jsonText = jsonMatch[0]
      }

      // LLMì´ ìì£¼ í•˜ëŠ” JSON ì‹¤ìˆ˜ ì •ë¦¬
      jsonText = jsonText
        // ì‹±ê¸€ì¿¼íŠ¸ â†’ ë”ë¸”ì¿¼íŠ¸ (ì†ì„±ëª…ê³¼ ë¬¸ìì—´ ê°’)
        .replace(/(\s*)'([^']+)'(\s*:)/g, '$1"$2"$3')  // í‚¤: 'key': â†’ "key":
        .replace(/:\s*'([^']*)'/g, ': "$1"')           // ê°’: : 'value' â†’ : "value"
        // trailing comma ì œê±° (ë§ˆì§€ë§‰ , ë’¤ì— } ë˜ëŠ” ])
        .replace(/,(\s*[}\]])/g, '$1')
        // ì£¼ì„ ì œê±°
        .replace(/\/\/[^\n]*/g, '')
        .replace(/\/\*[\s\S]*?\*\//g, '')
        // ì¤„ë°”ê¿ˆ ë¬¸ìì—´ ë‚´ ì´ìŠ¤ì¼€ì´í”„
        .replace(/:\s*"([^"]*)\n([^"]*)"/g, ': "$1\\n$2"')

      console.log('ğŸ“ Cleaned JSON (first 300):', jsonText.substring(0, 300))

      // JSON íŒŒì‹±
      const parsed = JSON.parse(jsonText)
      return parsed as T
    } catch (error: any) {
      if (error instanceof SyntaxError) {
        throw new GeminiApiError(
          `JSON íŒŒì‹± ì‹¤íŒ¨: ${error.message}`,
          'JSON_PARSE_ERROR',
          error
        )
      }
      throw error
    }
  }

  // ============================================
  // ìŠ¤íŠ¸ë¦¬ë° ìƒì„± (ì‹¤ì‹œê°„ ì‘ë‹µ)
  // ============================================

  async *generateTextStream(
    prompt: string,
    options: GeminiGenerationOptions = {}
  ): AsyncGenerator<string, void, unknown> {
    try {
      const generationConfig: GenerationConfig = {
        temperature: options.temperature ?? DEFAULT_TEMPERATURE,
        maxOutputTokens: options.maxOutputTokens ?? DEFAULT_MAX_TOKENS,
        topP: options.topP,
        topK: options.topK,
      }

      const result = await this.model.generateContentStream({
        contents: [{ role: 'user', parts: [{ text: prompt }] }],
        generationConfig,
      })

      for await (const chunk of result.stream) {
        const chunkText = chunk.text()
        if (chunkText) {
          yield chunkText
        }
      }
    } catch (error: any) {
      console.error('Gemini ìŠ¤íŠ¸ë¦¬ë° ì—ëŸ¬:', error)
      throw new GeminiApiError(
        `ìŠ¤íŠ¸ë¦¬ë° ìƒì„± ì‹¤íŒ¨: ${error.message}`,
        'STREAM_ERROR',
        error
      )
    }
  }

  // ============================================
  // ëŒ€í™” ì„¸ì…˜ ìƒì„±
  // ============================================

  createChatSession(systemInstruction?: string) {
    const chat = this.model.startChat({
      history: systemInstruction
        ? [
            {
              role: 'user',
              parts: [{ text: `ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­: ${systemInstruction}` }],
            },
            {
              role: 'model',
              parts: [{ text: 'ì´í•´í–ˆìŠµë‹ˆë‹¤. ì§€ì‹œì‚¬í•­ì„ ë”°ë¥´ê² ìŠµë‹ˆë‹¤.' }],
            },
          ]
        : [],
    })

    return {
      sendMessage: async (message: string): Promise<string> => {
        const result = await chat.sendMessage(message)
        return result.response.text()
      },
      sendMessageStream: async function* (message: string): AsyncGenerator<string> {
        const result = await chat.sendMessageStream(message)
        for await (const chunk of result.stream) {
          yield chunk.text()
        }
      },
    }
  }

  // ============================================
  // í† í° ìˆ˜ ê³„ì‚° (ì¶”ì •)
  // ============================================

  async countTokens(text: string): Promise<number> {
    try {
      const result = await this.model.countTokens(text)
      return result.totalTokens
    } catch (error: any) {
      console.warn('í† í° ê³„ì‚° ì‹¤íŒ¨, ì¶”ì •ê°’ ë°˜í™˜:', error.message)
      // ëŒ€ëµì ì¸ ì¶”ì • (1 í† í° â‰ˆ 4 ë¬¸ì)
      return Math.ceil(text.length / 4)
    }
  }

  // ============================================
  // ì—°ê²° í…ŒìŠ¤íŠ¸
  // ============================================

  async testConnection(): Promise<boolean> {
    try {
      const response = await this.generateText('Hello, are you working?', {
        maxOutputTokens: 50,
      })
      return response.text.length > 0
    } catch (error) {
      console.error('Gemini ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', error)
      return false
    }
  }

  // ============================================
  // ëª¨ë¸ ì •ë³´
  // ============================================

  getModelInfo(): {
    name: string
    apiKey: string
    description: string
  } {
    return {
      name: GEMINI_MODEL,
      apiKey: this.apiKey.substring(0, 10) + '...',
      description: 'Google Gemini 2.0 Flash - Fast and cost-effective',
    }
  }
}

// ============================================
// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
// ============================================

let geminiClientInstance: GeminiClient | null = null

export function getGeminiClient(): GeminiClient {
  if (!geminiClientInstance) {
    geminiClientInstance = new GeminiClient()
  }
  return geminiClientInstance
}

export default getGeminiClient
